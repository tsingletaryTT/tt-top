# SPDX-FileCopyrightText: Â© 2023 Tenstorrent Inc.
# SPDX-License-Identifier: Apache-2.0

"""
TT-Top Live Monitor Widget (Cross-compatible version)

A real-time hardware monitoring display inspired by htop, Logstalgia, and Orca.
Simplified for compatibility across different Textual versions.
"""

import time
from typing import Dict, List
from textual.widget import Widget
from textual.widgets import Static
from textual.containers import Container, Vertical
from textual.app import ComposeResult
from textual.events import Key
from textual.binding import Binding
from tt_top.tt_smi_backend import TTSMIBackend
from tt_top import constants

# Cross-platform ScrollView import for Textual compatibility
try:
    from textual.widgets import ScrollView
except ImportError:
    try:
        from textual.containers import ScrollableContainer as ScrollView
    except ImportError:
        try:
            from textual.scroll_view import ScrollView
        except ImportError:
            # Final fallback: use Container if ScrollView not available
            ScrollView = Container


class TTTopDisplay(Static):
    """
    Single static widget that renders all TT-Top components.
    More compatible across Textual versions.
    """

    def __init__(self, backend: TTSMIBackend, **kwargs):
        super().__init__(**kwargs)
        self.backend = backend
        self.animation_frame = 0
        self.start_time = time.time()  # Track when the display was created

    def on_mount(self) -> None:
        """Set up dynamic periodic updates with hardware safety coordination"""
        # Start with initial safety-aware interval instead of fixed interval
        self._schedule_safe_update()

    def _schedule_safe_update(self) -> None:
        """Schedule next update using safety coordinator's recommended interval

        Uses the hardware safety coordinator to determine appropriate polling
        frequency based on active workloads, PCIe error state, and system load.
        """
        try:
            # Get safe polling interval from safety coordinator
            safe_interval = self.backend.safety_coordinator.get_safe_poll_interval()

            # Handle disabled monitoring (infinite interval)
            if safe_interval == float('inf'):
                # Monitoring disabled due to errors - check again in 30 seconds
                safe_interval = 30.0

            # Schedule next update with dynamic interval
            self.set_timer(safe_interval, self._update_display)

        except Exception as e:
            # Fallback to fixed interval on error
            from tt_top import constants
            self.set_timer(constants.GUI_INTERVAL_TIME, self._update_display)

    def _update_display(self) -> None:
        """Update the display with current data using dynamic safety-aware polling

        Updates telemetry through the safety coordinator, then schedules the
        next update based on current system workload and hardware state.
        """
        try:
            # Update backend telemetry (now includes safety coordination)
            self.backend.update_telem()
            self.animation_frame += 1

            # Generate the complete display
            content = self._render_complete_display()
            self.update(content)

        except Exception as e:
            # Handle errors gracefully
            self.update(f"[red]Error updating display: {e}[/red]")

        finally:
            # Always schedule next update with dynamic interval
            # This creates continuous adaptive polling that responds to workload changes
            self._schedule_safe_update()

    def _should_show_logo(self) -> bool:
        """Check if logo should be displayed (only for first 5 seconds)"""
        return (time.time() - self.start_time) < 5.0

    def _get_status_color(self, temperature: float, power: float) -> str:
        """Get color based on hardware status - systematic color mapping"""
        if temperature > 80:
            return "bold red"
        elif temperature > 65:
            return "orange3"  # Brown/orange instead of yellow
        elif power > 200:
            return "orange3"  # Brown/orange for high power
        elif power > 50:
            return "bright_green"
        else:
            return "bright_cyan"

    def _get_temperature_color(self, temperature: float) -> str:
        """Get temperature-specific color coding"""
        if temperature > 80:
            return "bold red"
        elif temperature > 65:
            return "orange3"  # Brown/orange instead of yellow
        elif temperature > 45:
            return "orange1"  # Lighter orange for warm
        else:
            return "bright_cyan"

    def _get_power_color(self, power: float) -> str:
        """Get power-specific color coding"""
        if power > 75:
            return "bold red"
        elif power > 50:
            return "orange3"  # Brown/orange instead of yellow
        elif power > 25:
            return "bright_green"
        else:
            return "bright_cyan"

    def _create_border_line(self, content: str = "", style: str = "bright_cyan", end_char: str = "") -> str:
        """Create bordered line with consistent styling"""
        border_char = "â•‘" if not end_char else end_char
        return f"[{style}]{border_char}[/{style}] {content}"

    def _colorize_text(self, text: str, color: str) -> str:
        """Apply color markup to text"""
        return f"[{color}]{text}[/{color}]"

    def _get_status_indicator(self, power: float) -> tuple[str, str]:
        """Get status block and icon based on power level - returns (block, icon)"""
        if power > 50:
            return (self._colorize_text("â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ", "bold red"),
                   self._colorize_text("â—‰", "bold red"))
        elif power > 25:
            return (self._colorize_text("â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ", "bold orange3") + self._colorize_text("â–“â–“â–“â–“", "dim white"),
                   self._colorize_text("â—", "bold orange3"))
        elif power > 10:
            return (self._colorize_text("â–ˆâ–ˆâ–ˆâ–ˆ", "bright_green") + self._colorize_text("â–“â–“â–“â–“â–“â–“", "dim white"),
                   self._colorize_text("â—‹", "bright_green"))
        else:
            return (self._colorize_text("â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“", "dim white"),
                   self._colorize_text("Â·", "dim white"))

    def _get_device_status_text(self, device_idx: int) -> str:
        """Get intelligent device status text with appropriate colors"""
        workload = self.backend.detect_workload_state(device_idx)
        temp = float(self.backend.device_telemetrys[device_idx].get('asic_temperature', '0.0'))
        
        # Thermal states take precedence
        if temp > 85:
            return self._colorize_text("CRITICAL", "bold red")
        elif temp > 75:
            return self._colorize_text("HOT", "bold orange3")
        
        # Use intelligent workload detection
        return self._colorize_text(workload['name'], workload['color'])

    def _get_bandwidth_indicator(self, bandwidth: float) -> str:
        """Get bandwidth utilization indicator with colors"""
        if bandwidth > 50:
            return (self._colorize_text("â–“â–“", "bold red") +
                   self._colorize_text(f"{bandwidth:3.0f}", "orange1") + "  ")
        elif bandwidth > 25:
            return (self._colorize_text("â–’â–’", "bold orange3") +
                   self._colorize_text(f"{bandwidth:3.0f}", "bright_white") + "  ")
        elif bandwidth > 10:
            return (self._colorize_text("â–‘â–‘", "bright_green") +
                   self._colorize_text(f"{bandwidth:3.0f}", "bright_cyan") + "  ")
        else:
            return "  " + self._colorize_text(f"{bandwidth:3.0f}", "dim white") + "  "

    def _get_event_color_and_text(self, device_idx: int, event_type: str) -> str:
        """Get intelligent event text using backend workload detection"""
        return self.backend.get_workload_event_text(device_idx, event_type)

    def _create_section_header(self, title: str, border_style: str = "bright_cyan") -> str:
        """Create section header with consistent formatting"""
        return f"[{border_style}]â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [bold bright_white]{title}[/bold bright_white][/{border_style}]"

    def _create_section_border(self, style: str = "bright_cyan") -> str:
        """Create section border line"""
        return f"[{style}]â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[/{style}]"

    def _create_bordered_line(self, content: str, style: str = "bright_cyan") -> str:
        """Create a bordered line with content"""
        return f"[{style}]â”‚[/{style}] {content}"

    def _create_section_footer(self, style: str = "bright_cyan") -> str:
        """Create section footer line"""
        return f"[{style}]â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[/{style}]"

    def _get_memory_channels_for_architecture(self, device_idx: int) -> int:
        """Get number of memory channels based on device architecture

        Returns the architecture-specific memory channel count:
        - Grayskull: 4 DDR channels
        - Wormhole: 8 DDR channels
        - Blackhole: 12 DDR channels
        """
        device = self.backend.devices[device_idx]
        if device.as_gs():
            return 4
        elif device.as_wh():
            return 8
        elif device.as_bh():
            return 12
        else:
            return 8  # Default fallback

    def _get_tensix_grid_size(self, device_idx: int) -> tuple[int, int]:
        """Get Tensix core grid dimensions for device architecture

        Returns (rows, cols) for the Tensix core array:
        - Grayskull: 10x12 grid
        - Wormhole: 8x10 grid (optimized layout)
        - Blackhole: 14x16 grid (largest array)
        """
        device = self.backend.devices[device_idx]
        if device.as_gs():
            return (10, 12)
        elif device.as_wh():
            return (8, 10)
        elif device.as_bh():
            return (14, 16)
        else:
            return (8, 10)  # Default fallback

    def _create_memory_hierarchy_matrix(self) -> List[str]:
        """Create enhanced 3-level memory hierarchy visualization

        Novel visualization showing DDR â†’ L2 â†’ L1 memory hierarchy
        with real-time utilization, bandwidth flow, and bottleneck detection.
        """
        lines = []
        lines.append(self._create_section_header("MEMORY HIERARCHY MATRIX"))

        # Add explanatory header with legend
        lines.append(self._create_bordered_line(
            self._colorize_text("Legend:", "bright_white") + " " +
            self._colorize_text("â–ˆâ–ˆ", "bold red") + " >90% " +
            self._colorize_text("â–“â–“", "orange3") + " 70-90% " +
            self._colorize_text("â–’â–’", "orange1") + " 40-70% " +
            self._colorize_text("â–‘â–‘", "bright_green") + " 10-40% " +
            self._colorize_text("Â·Â·", "dim white") + " <10% " +
            self._colorize_text("XX", "bold red") + " Error"
        ))
        lines.append(self._create_section_border())

        for i, device in enumerate(self.backend.devices):
            device_name = self.backend.get_device_name(device)[:3].upper()
            telem = self.backend.device_telemetrys[i]
            power = float(telem.get('power', '0.0'))
            temp = float(telem.get('asic_temperature', '0.0'))
            current = float(telem.get('current', '0.0'))

            # Create memory hierarchy visualization for this device
            memory_display = self._create_device_memory_matrix(i, device_name, power, current)
            lines.extend(memory_display)

            if i < len(self.backend.devices) - 1:
                lines.append(self._create_bordered_line(""))  # Separator between devices

        lines.append(self._create_section_footer())
        return lines

    def _create_device_memory_matrix(self, device_idx: int, device_name: str, power: float, current: float) -> List[str]:
        """Create memory matrix visualization for a single device

        Shows DDR channels, L2 cache banks, and L1 SRAM grid in aligned matrix format
        with real-time utilization data and data flow indicators.
        """
        lines = []

        # Device header with real-time stats
        power_color = self._get_power_color(power)
        lines.append(self._create_bordered_line(
            f"[bold bright_white]Device {device_idx}: {device_name}[/bold bright_white] â”‚ " +
            f"Power: [{power_color}]{power:5.1f}W[/{power_color}] â”‚ " +
            f"Current: [bright_green]{current:5.1f}A[/bright_green]"
        ))

        # Get architecture-specific parameters
        num_channels = self._get_memory_channels_for_architecture(device_idx)
        tensix_rows, tensix_cols = self._get_tensix_grid_size(device_idx)

        # DDR Channel Matrix (horizontal layout)
        ddr_line = self._create_ddr_channel_matrix(device_idx, num_channels, current)
        lines.append(self._create_bordered_line(f"DDR Channels: {ddr_line}"))

        # L2 Cache Banks (simulated based on power consumption)
        l2_line = self._create_l2_cache_matrix(power, num_channels)
        lines.append(self._create_bordered_line(f"L2 Cache:     {l2_line}"))

        # L1 SRAM Grid (compressed view of Tensix array)
        l1_lines = self._create_l1_sram_matrix(device_idx, tensix_rows, tensix_cols, power)
        for line in l1_lines:
            lines.append(self._create_bordered_line(f"L1 SRAM:      {line}"))

        # Memory bandwidth flow indicators
        flow_line = self._create_memory_flow_indicators(current, power)
        lines.append(self._create_bordered_line(f"Data Flow:    {flow_line}"))

        return lines

    def _create_ddr_channel_matrix(self, device_idx: int, num_channels: int, current: float) -> str:
        """Create DDR channel utilization matrix

        Shows real DDR training status and utilization based on current draw.
        Uses actual DDR_STATUS telemetry data where available.
        """
        try:
            # Get real DDR training status if available
            ddr_info = self.backend.smbus_telem_info[device_idx].get('DDR_STATUS', '0')
            if ddr_info and ddr_info != '0':
                return self._generate_real_ddr_pattern(ddr_info, num_channels, device_idx)
        except:
            pass

        # Fallback to current-based simulation
        channels = []
        base_utilization = min(int(current / 10), 9)  # Scale current to 0-9 range

        for i in range(num_channels):
            # Vary utilization per channel based on current and channel index
            channel_util = max(0, base_utilization - abs(i - num_channels//2))

            if channel_util >= 8:
                channels.append(self._colorize_text("â–ˆâ–ˆ", "bold red"))
            elif channel_util >= 6:
                channels.append(self._colorize_text("â–“â–“", "orange3"))
            elif channel_util >= 4:
                channels.append(self._colorize_text("â–’â–’", "orange1"))
            elif channel_util >= 2:
                channels.append(self._colorize_text("â–‘â–‘", "bright_green"))
            else:
                channels.append(self._colorize_text("Â·Â·", "dim white"))

        return " ".join(channels)

    def _create_l2_cache_matrix(self, power: float, num_channels: int) -> str:
        """Create L2 cache bank utilization matrix

        Simulates L2 cache utilization based on power consumption patterns.
        L2 cache acts as intermediate between DDR and L1, showing different patterns.
        """
        # L2 cache banks typically match DDR channel count
        cache_banks = []
        base_util = min(int(power / 15), 9)  # Different scaling for cache vs DDR

        for i in range(num_channels):
            # L2 utilization often shows hotspot patterns
            bank_util = base_util
            if i == num_channels // 2:  # Center bank typically more active
                bank_util = min(bank_util + 2, 9)
            elif i in [0, num_channels - 1]:  # Edge banks less active
                bank_util = max(bank_util - 2, 0)

            if bank_util >= 8:
                cache_banks.append(self._colorize_text("â–ˆâ–ˆ", "bold red"))
            elif bank_util >= 6:
                cache_banks.append(self._colorize_text("â–“â–“", "orange3"))
            elif bank_util >= 4:
                cache_banks.append(self._colorize_text("â–’â–’", "orange1"))
            elif bank_util >= 2:
                cache_banks.append(self._colorize_text("â–‘â–‘", "bright_green"))
            else:
                cache_banks.append(self._colorize_text("Â·Â·", "dim white"))

        return " ".join(cache_banks)

    def _create_l1_sram_matrix(self, device_idx: int, rows: int, cols: int, power: float) -> List[str]:
        """Create L1 SRAM grid visualization (compressed view)

        Shows compressed view of Tensix core L1 SRAM utilization.
        Each character represents multiple cores, showing hotspot patterns.
        """
        # Compress large grids into displayable format (max 12x8)
        display_rows = min(rows, 8)
        display_cols = min(cols, 12)

        # Calculate compression ratios
        row_ratio = rows / display_rows
        col_ratio = cols / display_cols

        grid_lines = []
        base_activity = min(int(power / 10), 9)

        for r in range(display_rows):
            row_chars = []
            for c in range(display_cols):
                # Create hotspot patterns - center more active, edges less
                distance_from_center = abs(r - display_rows//2) + abs(c - display_cols//2)
                activity = max(0, base_activity - distance_from_center)

                # Add some noise for realistic patterns
                activity += (self.animation_frame + r * display_cols + c) % 3 - 1
                activity = max(0, min(activity, 9))

                if activity >= 8:
                    row_chars.append(self._colorize_text("â–ˆ", "bold red"))
                elif activity >= 6:
                    row_chars.append(self._colorize_text("â–“", "orange3"))
                elif activity >= 4:
                    row_chars.append(self._colorize_text("â–’", "orange1"))
                elif activity >= 2:
                    row_chars.append(self._colorize_text("â–‘", "bright_green"))
                else:
                    row_chars.append(self._colorize_text("Â·", "dim white"))

            # Format row with compression info
            if len(grid_lines) == 0:
                row_str = "".join(row_chars) + f" [{rows}Ã—{cols} grid compressed]"
            else:
                row_str = "".join(row_chars)

            grid_lines.append(row_str)

        return grid_lines

    def _create_memory_flow_indicators(self, current: float, power: float) -> str:
        """Create memory data flow visualization

        Shows data movement between memory hierarchy levels using flow indicators.
        Flow intensity based on actual current draw and power consumption.
        """
        # Calculate flow intensities for different paths
        ddr_to_l2_flow = min(int(current / 8), 9)
        l2_to_l1_flow = min(int(power / 12), 9)

        # Create flow visualization
        flow_chars = []

        # DDR â†’ L2 flow
        if ddr_to_l2_flow >= 7:
            flow_chars.extend([self._colorize_text("â–¶â–¶â–¶", "bold red")])
        elif ddr_to_l2_flow >= 5:
            flow_chars.extend([self._colorize_text("â–¶â–¶â–·", "orange3")])
        elif ddr_to_l2_flow >= 3:
            flow_chars.extend([self._colorize_text("â–¶â–·â–¸", "orange1")])
        elif ddr_to_l2_flow >= 1:
            flow_chars.extend([self._colorize_text("â–·â–¸â–¹", "bright_green")])
        else:
            flow_chars.extend([self._colorize_text("Â·Â·Â·", "dim white")])

        flow_chars.append(" â†’ ")

        # L2 â†’ L1 flow
        if l2_to_l1_flow >= 7:
            flow_chars.extend([self._colorize_text("â–¶â–¶â–¶", "bold red")])
        elif l2_to_l1_flow >= 5:
            flow_chars.extend([self._colorize_text("â–¶â–¶â–·", "orange3")])
        elif l2_to_l1_flow >= 3:
            flow_chars.extend([self._colorize_text("â–¶â–·â–¸", "orange1")])
        elif l2_to_l1_flow >= 1:
            flow_chars.extend([self._colorize_text("â–·â–¸â–¹", "bright_green")])
        else:
            flow_chars.extend([self._colorize_text("Â·Â·Â·", "dim white")])

        # Add bandwidth estimates
        ddr_bandwidth = current * 8.5  # Approximate GB/s calculation
        l1_bandwidth = power * 12.0   # Approximate internal bandwidth

        flow_chars.extend([
            f" â”‚ DDR: {ddr_bandwidth:4.1f}GB/s â”‚ L1: {l1_bandwidth:4.1f}GB/s"
        ])

        return "".join(flow_chars)

    def _create_workload_detection_section(self) -> List[str]:
        """Create intelligent workload detection and analysis section

        Uses process analysis, command line parsing, and telemetry correlation
        to identify ML frameworks, model types, and workload characteristics
        running on the system that may be utilizing Tenstorrent hardware.
        """
        lines = []
        lines.append(self._create_section_header("WORKLOAD INTELLIGENCE ENGINE"))

        # Add detection methodology header
        lines.append(self._create_bordered_line(
            self._colorize_text("Detection Sources:", "bright_white") + " " +
            self._colorize_text("/proc filesystem", "bright_cyan") + " â€¢ " +
            self._colorize_text("Process cmdlines", "bright_cyan") + " â€¢ " +
            self._colorize_text("Memory patterns", "bright_cyan") + " â€¢ " +
            self._colorize_text("Telemetry correlation", "bright_cyan")
        ))
        lines.append(self._create_section_border())

        try:
            # Detect active ML workloads
            workloads = self._detect_ml_workloads()

            if not workloads:
                lines.append(self._create_bordered_line(
                    self._colorize_text("Status:", "bright_white") + " " +
                    self._colorize_text("No ML workloads detected", "orange1") + " " +
                    self._colorize_text("(Scanning /proc filesystem...)", "dim white")
                ))
            else:
                # Display detected workloads, filtering out unknowns
                known_workloads = [w for w in workloads if w['framework'] != 'unknown'
                                 and w['model_type'] != 'unknown'
                                 and w['workload_type'] != 'unknown']
                for workload in known_workloads[:5]:  # Show top 5 known workloads
                    workload_line = self._format_workload_display(workload)
                    lines.append(self._create_bordered_line(workload_line))

                # Workload summary statistics
                summary_line = self._create_workload_summary(workloads)
                lines.append(self._create_bordered_line(""))
                lines.append(self._create_bordered_line(summary_line))

        except Exception as e:
            # Graceful fallback for systems without /proc access
            lines.append(self._create_bordered_line(
                self._colorize_text("Status:", "bright_white") + " " +
                self._colorize_text("Workload detection unavailable", "orange3") + " " +
                self._colorize_text("(Requires Linux /proc filesystem)", "dim white")
            ))

        lines.append(self._create_section_footer())
        return lines

    def _detect_ml_workloads(self) -> List[dict]:
        """Detect machine learning workloads from system processes

        Uses multiple detection methods with fallbacks:
        1. psutil library (preferred - cross-platform, robust)
        2. subprocess ps command (Linux/Unix fallback)
        3. /proc filesystem (last resort Linux fallback)

        Returns list of detected workload dictionaries with framework,
        model type, resource usage, and confidence scores.
        """
        detected_workloads = []

        # Method 1: Try psutil first (most robust)
        try:
            import psutil
            detected_workloads = self._detect_ml_workloads_psutil()
            if detected_workloads:
                return detected_workloads
        except ImportError:
            pass
        except Exception:
            pass

        # Method 2: Try subprocess ps command (Unix/Linux systems)
        try:
            detected_workloads = self._detect_ml_workloads_ps()
            if detected_workloads:
                return detected_workloads
        except Exception:
            pass

        # Method 3: Fallback to /proc filesystem (Linux only, last resort)
        try:
            detected_workloads = self._detect_ml_workloads_proc()
        except Exception:
            pass

        return detected_workloads

    def _detect_ml_workloads_psutil(self) -> List[dict]:
        """Detect ML workloads using psutil library (preferred method)"""
        import psutil
        import re

        detected_workloads = []

        try:
            for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'memory_info', 'num_threads']):
                try:
                    proc_info = proc.info
                    if not proc_info['cmdline']:
                        continue

                    # Join command line arguments
                    cmdline = ' '.join(proc_info['cmdline'])
                    pid = proc_info['pid']

                    # Analyze for ML patterns
                    workload_info = self._analyze_cmdline_for_ml_patterns(
                        pid, cmdline, proc_info.get('memory_info'), proc_info.get('num_threads', 1)
                    )

                    if workload_info and workload_info['confidence'] > 0.3:
                        detected_workloads.append(workload_info)

                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    continue

        except Exception:
            return []

        detected_workloads.sort(key=lambda w: (w.get('correlation_score', 0), w['confidence']), reverse=True)
        return detected_workloads

    def _detect_ml_workloads_ps(self) -> List[dict]:
        """Detect ML workloads using ps subprocess command (Unix/Linux fallback)"""
        import subprocess
        import re

        detected_workloads = []

        try:
            # Use ps to get process information
            result = subprocess.run([
                'ps', 'axo', 'pid,command', '--no-headers'
            ], capture_output=True, text=True, timeout=5)

            if result.returncode != 0:
                return []

            for line in result.stdout.strip().split('\n'):
                if not line.strip():
                    continue

                # Parse ps output: PID followed by command
                parts = line.strip().split(None, 1)
                if len(parts) < 2:
                    continue

                try:
                    pid = int(parts[0])
                    cmdline = parts[1]

                    # Analyze for ML patterns
                    workload_info = self._analyze_cmdline_for_ml_patterns(pid, cmdline, None, 1)

                    if workload_info and workload_info['confidence'] > 0.3:
                        detected_workloads.append(workload_info)

                except ValueError:
                    continue

        except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError):
            return []

        detected_workloads.sort(key=lambda w: (w.get('correlation_score', 0), w['confidence']), reverse=True)
        return detected_workloads

    def _detect_ml_workloads_proc(self) -> List[dict]:
        """Detect ML workloads using /proc filesystem (Linux last resort)"""
        import os
        import glob
        import re

        detected_workloads = []

        try:
            # Scan all process directories in /proc
            for proc_dir in glob.glob('/proc/[0-9]*'):
                try:
                    pid = int(os.path.basename(proc_dir))

                    # Read process command line
                    cmdline_path = os.path.join(proc_dir, 'cmdline')
                    if os.path.exists(cmdline_path):
                        with open(cmdline_path, 'rb') as f:
                            cmdline_bytes = f.read()
                            cmdline = cmdline_bytes.replace(b'\x00', b' ').decode('utf-8', errors='ignore')

                        # Apply ML workload detection heuristics
                        workload_info = self._analyze_process_for_ml_patterns(pid, cmdline, proc_dir)

                        if workload_info and workload_info['confidence'] > 0.3:
                            detected_workloads.append(workload_info)

                except (ValueError, PermissionError, FileNotFoundError):
                    # Skip processes we can't access or that disappeared
                    continue

        except Exception:
            return []

        # Sort by confidence score and correlation strength
        detected_workloads.sort(key=lambda w: (w.get('correlation_score', 0), w['confidence']), reverse=True)
        return detected_workloads

    def _analyze_cmdline_for_ml_patterns(self, pid: int, cmdline: str, memory_info=None, num_threads: int = 1) -> dict:
        """Analyze command line for ML framework patterns (used by psutil and ps methods)"""
        import re

        # Framework detection patterns
        framework_patterns = {
            'pytorch': [
                r'python.*torch', r'torchrun', r'python.*transformers',
                r'python.*accelerate', r'python.*deepspeed', r'python.*lightning'
            ],
            'tensorflow': [
                r'python.*tensorflow', r'python.*tf\.', r'tf_cnn_benchmarks',
                r'python.*keras'
            ],
            'jax': [
                r'python.*jax', r'python.*flax', r'python.*optax',
                r'python.*haiku', r'python.*dm-haiku'
            ],
            'huggingface': [
                r'python.*transformers', r'python.*datasets', r'python.*accelerate',
                r'accelerate.*launch', r'python.*peft'
            ]
        }

        # Model type patterns
        model_patterns = {
            'llm': [
                r'gpt', r'bert', r'roberta', r'llama', r'mistral', r'falcon',
                r'bloom', r't5', r'bart', r'opt', r'palm', r'claude'
            ],
            'computer_vision': [
                r'resnet', r'vgg', r'inception', r'mobilenet', r'efficientnet',
                r'yolo', r'rcnn', r'ssd', r'unet', r'segformer'
            ],
            'audio_speech': [
                r'whisper', r'wav2vec', r'hubert', r'speechbrain', r'espnet'
            ]
        }

        # Workload type patterns
        workload_patterns = {
            'training': [r'train', r'training', r'fit', r'finetune', r'fine-tune'],
            'inference': [r'inference', r'infer', r'predict', r'generate', r'serve'],
            'evaluation': [r'eval', r'evaluate', r'test', r'benchmark']
        }

        cmdline_lower = cmdline.lower()

        # Detect framework
        detected_framework = 'unknown'
        framework_confidence = 0.0

        for framework, patterns in framework_patterns.items():
            for pattern in patterns:
                if re.search(pattern, cmdline_lower):
                    detected_framework = framework
                    framework_confidence = 0.8
                    break
            if framework_confidence > 0:
                break

        # Detect model type
        detected_model_type = 'unknown'
        model_confidence = 0.0

        for model_type, patterns in model_patterns.items():
            for pattern in patterns:
                if re.search(pattern, cmdline_lower):
                    detected_model_type = model_type
                    model_confidence = 0.7
                    break
            if model_confidence > 0:
                break

        # Detect workload type
        detected_workload_type = 'unknown'
        workload_confidence = 0.0

        for workload_type, patterns in workload_patterns.items():
            for pattern in patterns:
                if re.search(pattern, cmdline_lower):
                    detected_workload_type = workload_type
                    workload_confidence = 0.6
                    break
            if workload_confidence > 0:
                break

        # Calculate overall confidence
        overall_confidence = max(framework_confidence, model_confidence, workload_confidence)

        if overall_confidence > 0.3:
            # Estimate memory usage
            memory_gb = 0
            if memory_info:
                try:
                    # psutil memory_info has rss attribute
                    if hasattr(memory_info, 'rss'):
                        memory_gb = memory_info.rss / (1024 * 1024 * 1024)  # Convert to GB
                    else:
                        memory_gb = memory_info / (1024 * 1024 * 1024)  # Convert to GB
                except:
                    memory_gb = 0

            # Correlate with hardware telemetry
            resource_info = {
                'memory_gb': memory_gb,
                'threads': num_threads,
                'cpu_percent': 50 if memory_gb > 4 else 20  # Rough estimate
            }

            correlation_score = self._correlate_process_with_telemetry(pid, resource_info)

            return {
                'pid': pid,
                'cmdline': cmdline[:80] + '...' if len(cmdline) > 80 else cmdline,
                'framework': detected_framework,
                'model_type': detected_model_type,
                'workload_type': detected_workload_type,
                'confidence': overall_confidence,
                'correlation_score': correlation_score,
                'memory_gb': resource_info.get('memory_gb', 0),
                'thread_count': resource_info.get('threads', 1),
                'cpu_percent': resource_info.get('cpu_percent', 0)
            }

        return None

    def _analyze_process_for_ml_patterns(self, pid: int, cmdline: str, proc_dir: str) -> dict:
        """Analyze individual process for ML framework patterns

        Comprehensive analysis of process characteristics including:
        - Command line pattern matching for ML frameworks
        - Memory usage analysis for model size estimation
        - File descriptor analysis for model/data files
        - Resource usage patterns for workload classification
        """

        # Framework detection patterns
        framework_patterns = {
            'pytorch': [
                r'python.*torch', r'torchrun', r'python.*transformers',
                r'python.*accelerate', r'python.*deepspeed', r'python.*lightning'
            ],
            'tensorflow': [
                r'python.*tensorflow', r'python.*tf\.', r'tf_cnn_benchmarks',
                r'python.*keras'
            ],
            'jax': [
                r'python.*jax', r'python.*flax', r'python.*optax',
                r'python.*haiku', r'python.*dm-haiku'
            ],
            'huggingface': [
                r'python.*transformers', r'python.*datasets', r'python.*accelerate',
                r'accelerate.*launch', r'python.*peft'
            ]
        }

        # Model type patterns
        model_patterns = {
            'llm': [
                r'gpt', r'bert', r'roberta', r'llama', r'mistral', r'falcon',
                r'bloom', r't5', r'bart', r'opt', r'palm', r'claude'
            ],
            'computer_vision': [
                r'resnet', r'vgg', r'inception', r'mobilenet', r'efficientnet',
                r'yolo', r'rcnn', r'ssd', r'unet', r'segformer'
            ],
            'audio_speech': [
                r'whisper', r'wav2vec', r'hubert', r'speechbrain', r'espnet'
            ]
        }

        # Workload type patterns
        workload_patterns = {
            'training': [r'train', r'training', r'fit', r'finetune', r'fine-tune'],
            'inference': [r'inference', r'infer', r'predict', r'generate', r'serve'],
            'evaluation': [r'eval', r'evaluate', r'test', r'benchmark']
        }

        cmdline_lower = cmdline.lower()

        # Detect framework
        detected_framework = 'unknown'
        framework_confidence = 0.0

        for framework, patterns in framework_patterns.items():
            for pattern in patterns:
                if re.search(pattern, cmdline_lower):
                    detected_framework = framework
                    framework_confidence = 0.8
                    break
            if framework_confidence > 0:
                break

        # Detect model type
        detected_model_type = 'unknown'
        model_confidence = 0.0

        for model_type, patterns in model_patterns.items():
            for pattern in patterns:
                if re.search(pattern, cmdline_lower):
                    detected_model_type = model_type
                    model_confidence = 0.7
                    break
            if model_confidence > 0:
                break

        # Detect workload type
        detected_workload_type = 'unknown'
        workload_confidence = 0.0

        for workload_type, patterns in workload_patterns.items():
            for pattern in patterns:
                if re.search(pattern, cmdline_lower):
                    detected_workload_type = workload_type
                    workload_confidence = 0.6
                    break
            if workload_confidence > 0:
                break

        # Analyze resource usage if we detected ML patterns
        overall_confidence = max(framework_confidence, model_confidence, workload_confidence)

        if overall_confidence > 0.3:
            resource_info = self._analyze_process_resources(pid, proc_dir)

            # Correlate with current hardware telemetry
            correlation_score = self._correlate_process_with_telemetry(pid, resource_info)

            return {
                'pid': pid,
                'cmdline': cmdline[:80] + '...' if len(cmdline) > 80 else cmdline,
                'framework': detected_framework,
                'model_type': detected_model_type,
                'workload_type': detected_workload_type,
                'confidence': overall_confidence,
                'correlation_score': correlation_score,
                'memory_gb': resource_info.get('memory_gb', 0),
                'thread_count': resource_info.get('threads', 1),
                'cpu_percent': resource_info.get('cpu_percent', 0)
            }

        return None

    def _analyze_process_resources(self, pid: int, proc_dir: str) -> dict:
        """Analyze process resource usage patterns for ML workload characteristics

        Examines memory usage, thread count, and CPU utilization to help
        classify workload types and estimate model sizes.
        """
        resource_info = {}

        try:
            # Memory analysis from /proc/PID/status
            status_path = os.path.join(proc_dir, 'status')
            if os.path.exists(status_path):
                with open(status_path, 'r') as f:
                    status_content = f.read()

                # Extract memory information (values in KB)
                vm_rss_match = re.search(r'VmRSS:\s*(\d+)\s*kB', status_content)
                vm_size_match = re.search(r'VmSize:\s*(\d+)\s*kB', status_content)
                threads_match = re.search(r'Threads:\s*(\d+)', status_content)

                if vm_rss_match:
                    resource_info['memory_gb'] = int(vm_rss_match.group(1)) / (1024 * 1024)
                if vm_size_match:
                    resource_info['vm_size_gb'] = int(vm_size_match.group(1)) / (1024 * 1024)
                if threads_match:
                    resource_info['threads'] = int(threads_match.group(1))

            # CPU usage analysis would require temporal sampling
            # For now, use simplified heuristics based on memory patterns
            memory_gb = resource_info.get('memory_gb', 0)
            threads = resource_info.get('threads', 1)

            # Estimate CPU usage based on memory and thread patterns
            if memory_gb > 10 and threads > 8:
                resource_info['cpu_percent'] = 70  # High CPU estimate
            elif memory_gb > 4 and threads > 4:
                resource_info['cpu_percent'] = 40  # Medium CPU estimate
            else:
                resource_info['cpu_percent'] = 10  # Low CPU estimate

        except (PermissionError, FileNotFoundError):
            # Process may have disappeared or we lack permissions
            pass

        return resource_info

    def _correlate_process_with_telemetry(self, pid: int, resource_info: dict) -> float:
        """Correlate process activity with hardware telemetry patterns

        Analyzes current hardware power consumption, temperature, and memory
        usage patterns to estimate likelihood that this process is driving
        hardware utilization on Tenstorrent devices.
        """

        try:
            # Get current average hardware utilization across all devices
            total_power = sum(float(self.backend.device_telemetrys[i].get('power', '0'))
                            for i in range(len(self.backend.devices)))
            avg_power = total_power / max(len(self.backend.devices), 1)

            total_current = sum(float(self.backend.device_telemetrys[i].get('current', '0'))
                              for i in range(len(self.backend.devices)))
            avg_current = total_current / max(len(self.backend.devices), 1)

            # Correlation heuristics based on resource patterns
            correlation_score = 0.0

            # High memory usage processes more likely to drive hardware
            memory_gb = resource_info.get('memory_gb', 0)
            if memory_gb > 8:  # Large models
                correlation_score += 0.4
            elif memory_gb > 4:  # Medium models
                correlation_score += 0.2

            # High thread count suggests compute-intensive workload
            threads = resource_info.get('threads', 1)
            if threads > 16:
                correlation_score += 0.3
            elif threads > 8:
                correlation_score += 0.2

            # Correlate with actual hardware power consumption
            if avg_power > 60:  # High power usage
                correlation_score += 0.3
            elif avg_power > 30:  # Medium power usage
                correlation_score += 0.2

            # Current draw correlation (more precise than power)
            if avg_current > 40:
                correlation_score += 0.2
            elif avg_current > 20:
                correlation_score += 0.1

            return min(correlation_score, 1.0)  # Cap at 1.0

        except Exception:
            return 0.1  # Low default correlation

    def _format_workload_display(self, workload: dict) -> str:
        """Format workload information for display in TT-Top

        Creates a comprehensive single-line display showing framework,
        model type, resource usage, and correlation with hardware activity.
        """

        # Framework color coding
        framework_colors = {
            'pytorch': 'orange1',
            'tensorflow': 'bright_blue',
            'jax': 'bright_green',
            'huggingface': 'bright_magenta',
            'unknown': 'dim white'
        }

        # Workload type indicators
        workload_icons = {
            'training': 'ğŸ”¥',
            'inference': 'âš¡',
            'evaluation': 'ğŸ“Š',
            'unknown': 'â“'
        }

        framework = workload['framework']
        framework_color = framework_colors.get(framework, 'dim white')
        workload_icon = workload_icons.get(workload['workload_type'], 'â“')

        # Format the display line
        pid_str = f"PID:{workload['pid']:5d}"
        framework_str = self._colorize_text(framework.upper()[:8], framework_color)
        model_type_str = self._colorize_text(workload['model_type'].upper()[:6], 'bright_cyan')

        # Resource usage with appropriate colors
        memory_gb = workload.get('memory_gb', 0)
        memory_color = 'bold red' if memory_gb > 16 else 'orange3' if memory_gb > 8 else 'bright_green'
        memory_str = self._colorize_text(f"{memory_gb:4.1f}GB", memory_color)

        # Correlation strength indicator
        correlation = workload.get('correlation_score', 0)
        if correlation > 0.7:
            correlation_str = self._colorize_text("â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ", "bright_green")
        elif correlation > 0.5:
            correlation_str = self._colorize_text("â–ˆâ–ˆâ–ˆâ–ˆâ–“", "orange1")
        elif correlation > 0.3:
            correlation_str = self._colorize_text("â–ˆâ–ˆâ–ˆâ–“â–“", "orange3")
        else:
            correlation_str = self._colorize_text("â–ˆâ–ˆâ–“â–“â–“", "dim white")

        # Confidence indicator
        confidence = workload['confidence']
        confidence_str = f"{confidence*100:3.0f}%"
        confidence_color = 'bright_green' if confidence > 0.7 else 'orange3' if confidence > 0.5 else 'dim white'

        return (f"{workload_icon} {pid_str} â”‚ {framework_str} â”‚ {model_type_str} â”‚ "
                f"RAM:{memory_str} â”‚ Correlation:{correlation_str} â”‚ "
                f"Confidence:{self._colorize_text(confidence_str, confidence_color)}")

    def _create_workload_summary(self, workloads: List[dict]) -> str:
        """Create summary statistics of detected workloads

        Provides overview of detected frameworks, model types, and
        estimated hardware utilization attribution.

        Only counts KNOWN workloads - filters out unknown processes
        to match the display logic and provide accurate ML job counts.
        """

        # Filter out unknown workloads to match display behavior
        known_workloads = [w for w in workloads if w['framework'] != 'unknown'
                         and w['model_type'] != 'unknown'
                         and w['workload_type'] != 'unknown']

        if not known_workloads:
            return self._colorize_text("No identified ML workloads found", "dim white")

        # Count frameworks (only known ones)
        framework_counts = {}
        model_type_counts = {}
        workload_type_counts = {}

        total_memory = 0
        high_correlation_count = 0

        for workload in known_workloads:  # Only count known workloads
            # Count frameworks
            framework = workload['framework']
            framework_counts[framework] = framework_counts.get(framework, 0) + 1

            # Count model types
            model_type = workload['model_type']
            model_type_counts[model_type] = model_type_counts.get(model_type, 0) + 1

            # Count workload types
            workload_type = workload['workload_type']
            workload_type_counts[workload_type] = workload_type_counts.get(workload_type, 0) + 1

            # Accumulate stats
            total_memory += workload.get('memory_gb', 0)
            if workload.get('correlation_score', 0) > 0.5:
                high_correlation_count += 1

        # Format summary (only known processes counted)
        total_processes = len(known_workloads)
        dominant_framework = max(framework_counts.items(), key=lambda x: x[1])[0]
        dominant_model_type = max(model_type_counts.items(), key=lambda x: x[1])[0]

        summary_parts = [
            f"[bright_white]Found {total_processes} ML processes[/bright_white]",
            f"[bright_cyan]Primary: {dominant_framework.upper()}[/bright_cyan]",
            f"[orange1]Models: {dominant_model_type.upper()}[/orange1]",
            f"[bright_green]Total RAM: {total_memory:4.1f}GB[/bright_green]",
            f"[orange3]HW Correlation: {high_correlation_count}/{total_processes}[/orange3]"
        ]

        return " â”‚ ".join(summary_parts)

    def _render_complete_display(self) -> str:
        """Render TT-Top with retro BBS/terminal aesthetic"""
        lines = []

        # Show logo only for first 5 seconds
        if self._should_show_logo():
            lines.extend(self._create_compact_header())
            lines.append("")

        # Main BBS-style display
        lines.extend(self._create_bbs_main_display())

        return "\n".join(lines)

    def _create_memory_topology(self) -> List[str]:
        """Create memory topology visualization with real DDR telemetry data"""
        lines = []
        lines.append("Real Memory Topology & DDR Status")
        lines.append("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")

        for i, device in enumerate(self.backend.devices):
            device_name = self.backend.get_device_name(device)[:3].upper()
            telem = self.backend.device_telemetrys[i]
            power = float(telem.get('power', '0.0'))
            temp = float(telem.get('asic_temperature', '0.0'))

            # Get real DDR information from backend
            try:
                ddr_speed = self.backend.get_dram_speed(i)
                ddr_trained = self.backend.get_dram_training_status(i)
                ddr_info = self.backend.smbus_telem_info[i].get('DDR_STATUS', '0')
            except:
                ddr_speed = "N/A"
                ddr_trained = False
                ddr_info = "0"

            # Real memory bank visualization based on DDR status
            if ddr_trained:
                # Show trained memory channels
                if device.as_wh():  # Wormhole has 8 channels
                    channels = 8
                    mem_pattern = self._generate_real_ddr_pattern(ddr_info, channels, i)
                elif device.as_gs():  # Grayskull has 4 channels
                    channels = 4
                    mem_pattern = self._generate_real_ddr_pattern(ddr_info, channels, i)
                else:  # Blackhole
                    channels = 12  # Blackhole has more memory channels
                    mem_pattern = self._generate_real_ddr_pattern(ddr_info, channels, i)
                mem_state = "TRN"  # Trained
            else:
                mem_pattern = "â—¯" * 8  # Untrained channels
                mem_state = "UNT"  # Untrained

            # Interconnect visualization
            if i == 0:
                connector = "â”Œâ”€"
            elif i == len(self.backend.devices) - 1:
                connector = "â””â”€"
            else:
                connector = "â”œâ”€"

            # Real DDR status line
            line = f"â”‚{connector}{device_name}[{mem_state}] {mem_pattern} {ddr_speed:>4} â”‚"
            lines.append(line)

            # Show real memory bandwidth based on current telemetry
            current = float(telem.get('current', '0.0'))
            bandwidth = min(int(current / 5), 40)  # Scale to line width
            flow_line = self._create_data_flow_line(bandwidth, i)
            lines.append(f"â”‚  MEM: {flow_line[:40]:40} â”‚")

        lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        lines.append("Legend: TRN=Trained UNT=Untrained â—=Active Channel â—¯=Idle")
        return lines

    def _generate_memory_pattern(self, power_watts: float, device_idx: int) -> str:
        """Generate memory bank visualization based on actual power consumption"""
        # Memory banks - show actual activity level, not fake animation
        banks = ["â—¯"] * 8

        # Calculate how many banks to light up based on real power consumption
        # Scale power to 0-8 banks (assuming 100W is max)
        active_banks = min(int((power_watts / 100.0) * 8), 8)

        # Light up banks from left to right based on actual power
        # No fake animation - just real data representation
        for i in range(active_banks):
            banks[i] = "â—"

        return "".join(banks)

    def _generate_real_ddr_pattern(self, ddr_status: str, channels: int, device_idx: int) -> str:
        """Generate real DDR channel visualization based on actual hardware status"""
        try:
            status_value = int(ddr_status, 16) if ddr_status != "0" else 0
        except:
            status_value = 0

        # Create channel indicators based on real DDR status
        channel_indicators = []
        for i in range(min(channels, 8)):  # Limit display to 8 for space
            # Extract 4-bit status for each channel
            channel_status = (status_value >> (4 * i)) & 0xF

            # DDR status meanings: 0=untrained, 1=training, 2=trained, 3+=error states
            if channel_status == 2:  # Trained and active
                channel_indicators.append("â—")
            elif channel_status == 1:  # Training in progress
                # Animate training channels
                if (self.animation_frame + i) % 4 < 2:
                    channel_indicators.append("â—")
                else:
                    channel_indicators.append("â—‘")
            elif channel_status >= 3:  # Error states
                channel_indicators.append("âœ—")
            else:  # Untrained
                channel_indicators.append("â—¯")

        # Pad to consistent length
        while len(channel_indicators) < 8:
            channel_indicators.append("â—¯")

        return "".join(channel_indicators)

    def _create_data_flow_line(self, current_draw: float, device_idx: int) -> str:
        """Create data flow visualization based on actual current draw"""
        base_pattern = "âˆ™" * 20

        # Only show flow if there's actual current activity
        if current_draw < 5.0:  # Very low current = no meaningful flow
            return base_pattern

        # Calculate flow intensity based on real current draw
        flow_intensity = min(int(current_draw / 10), 8)  # Scale to 0-8 range
        if flow_intensity == 0:
            return base_pattern

        # Different flow characters for different intensity levels
        if current_draw > 50:
            flow_char = "â–¶"  # High current
        elif current_draw > 25:
            flow_char = "â–·"  # Medium current
        elif current_draw > 10:
            flow_char = "â–¸"  # Low current
        else:
            flow_char = "â–¹"  # Minimal current

        # Create flow pattern based on actual activity, not fake animation
        result = list(base_pattern)

        # Show steady flow pattern - density reflects real current
        spacing = max(1, 20 // flow_intensity)
        for i in range(0, 20, spacing):
            if i < len(result):
                result[i] = flow_char

        return "".join(result)

    def _create_activity_heatmap(self) -> List[str]:
        """Create real-time activity heatmap"""
        lines = []
        lines.append("Activity Heatmap (Last 60s)")
        lines.append("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")

        # Temporal heatmap - what static tabs can't show
        for i, device in enumerate(self.backend.devices):
            device_name = self.backend.get_device_name(device)[:10]
            telem = self.backend.device_telemetrys[i]

            # Create activity history visualization
            activity_history = self._get_activity_history(i)
            heatmap_line = self._create_heatmap_line(activity_history)

            # Current values
            power = float(telem.get('power', '0.0'))
            temp = float(telem.get('asic_temperature', '0.0'))

            line = f"â”‚{device_name:10} {heatmap_line} {power:5.1f}Wâ”‚"
            lines.append(line)

        # Time axis
        lines.append("â”‚Time:       60s    30s     10s    now â”‚")
        lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        return lines

    def _get_activity_history(self, device_idx: int) -> List[float]:
        """Simulate activity history (in real app, maintain rolling buffer)"""
        # Generate realistic activity pattern over time
        history = []
        for t in range(20):  # 20 time points
            base_activity = 30 + device_idx * 15
            # Add some realistic variation based on time and device
            variation = 10 * (1 + 0.5 * ((self.animation_frame + t + device_idx * 5) % 20) / 10)
            activity = max(0, base_activity + variation)
            history.append(activity)
        return history

    def _create_heatmap_line(self, history: List[float]) -> str:
        """Create heatmap visualization of activity over time"""
        chars = " â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆ"
        result = ""

        for value in history:
            intensity = min(int(value / 12), len(chars) - 1)  # Scale to char range
            result += chars[intensity]

        return result

    def _create_bandwidth_utilization(self) -> List[str]:
        """Create real-time bandwidth utilization graph"""
        lines = []
        lines.append("Interconnect Bandwidth Utilization")
        lines.append("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")

        # Show bandwidth between devices (what static tabs can't show)
        total_devices = len(self.backend.devices)

        for i in range(total_devices):
            device_name = self.backend.get_device_name(self.backend.devices[i])[:8]

            # Simulate interconnect utilization
            utilizations = []
            for j in range(total_devices):
                if i == j:
                    utilizations.append("  â”€â”€  ")  # Self
                else:
                    # Calculate "bandwidth" between devices
                    telem_i = self.backend.device_telemetrys[i]
                    telem_j = self.backend.device_telemetrys[j]

                    current_i = float(telem_i.get('current', '0.0'))
                    current_j = float(telem_j.get('current', '0.0'))

                    # Simulate interconnect activity
                    bandwidth = min(abs(current_i - current_j) * 2, 99)

                    if bandwidth > 50:
                        utilizations.append(f"{bandwidth:4.0f}â–“")
                    elif bandwidth > 25:
                        utilizations.append(f"{bandwidth:4.0f}â–’")
                    elif bandwidth > 10:
                        utilizations.append(f"{bandwidth:4.0f}â–‘")
                    else:
                        utilizations.append(f"{bandwidth:4.0f} ")

            line = f"â”‚{device_name:8} â”‚ " + " ".join(utilizations) + " â”‚"
            lines.append(line)

        # Footer with device labels
        device_labels = [self.backend.get_device_name(d)[:8] for d in self.backend.devices]
        header = "â”‚" + " " * 10 + "â”‚ " + " ".join(f"{name:5}" for name in device_labels) + " â”‚"
        lines.insert(2, header)  # Insert after title and top border
        lines.insert(3, "â”‚" + "â”€" * 10 + "â”¼" + "â”€" * (len(device_labels) * 6 + len(device_labels) - 1) + "â”€â”‚")

        lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        return lines

    def _create_live_process_insights(self) -> List[str]:
        """Create process insights with temporal patterns"""
        lines = []
        lines.append("Live Process Analysis (Trends & Patterns)")
        lines.append("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        lines.append("â”‚ID â”‚Device    â”‚Power â”‚Trendâ”‚Load â”‚Efficiencyâ”‚Thermal â”‚Memory â”‚Utilizationâ”‚")
        lines.append("â”œâ”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")

        for i, device in enumerate(self.backend.devices):
            device_name = self.backend.get_device_name(device)[:8]
            telem = self.backend.device_telemetrys[i]

            power = float(telem.get('power', '0.0'))
            voltage = float(telem.get('voltage', '0.0'))
            current = float(telem.get('current', '0.0'))
            temp = float(telem.get('asic_temperature', '0.0'))

            # Calculate insights not available in static tabs
            efficiency = (power / max(temp - 25, 1)) if temp > 25 else 0  # Power per degree above ambient
            load_pattern = self._calculate_load_pattern(i)
            trend = self._calculate_trend(i, power)
            thermal_state = "CRIT" if temp > 85 else "WARN" if temp > 75 else "OK"
            memory_util = min(int(current / 2), 99)  # Approximate memory utilization
            utilization = f"{int((power/100)*100):2d}%"

            line = f"â”‚{i:2d} â”‚{device_name:8} â”‚{power:5.1f}Wâ”‚{trend:4s}â”‚{load_pattern:4s}â”‚{efficiency:9.2f}â”‚{thermal_state:7}â”‚{memory_util:2d}%   â”‚{utilization:>10}â”‚"
            lines.append(line)

        lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        lines.append("Efficiency=Power/ThermalRise | Trend=5s avg | Load=Activity pattern")

        return lines

    def _calculate_load_pattern(self, device_idx: int) -> str:
        """Calculate load pattern (what static displays can't show)"""
        # Analyze recent activity pattern
        recent_frames = [
            (self.animation_frame - i + device_idx * 2) % 60 for i in range(5)
        ]

        if max(recent_frames) - min(recent_frames) > 30:
            return "SPKY"  # Spiky
        elif all(f > 40 for f in recent_frames):
            return "HIGH"  # Consistently high
        elif all(f < 20 for f in recent_frames):
            return "LOW"   # Consistently low
        else:
            return "MED"   # Medium/variable

    def _calculate_trend(self, device_idx: int, current_power: float) -> str:
        """Calculate power trend over recent frames"""
        # Simulate trend calculation (in real app, maintain history)
        trend_factor = (self.animation_frame + device_idx) % 10 - 5

        if trend_factor > 2:
            return "UPâ†—"
        elif trend_factor < -2:
            return "DNâ†˜"
        else:
            return "STBâ†’"

    def _combine_sections(self, left: List[str], right: List[str]) -> List[str]:
        """Combine two sections side by side"""
        combined = []
        max_lines = max(len(left), len(right))

        for i in range(max_lines):
            left_line = left[i] if i < len(left) else " " * 40
            right_line = right[i] if i < len(right) else " " * 40
            combined.append(f"{left_line} {right_line}")

        return combined

    def _create_unified_display(self) -> List[str]:
        """Create a unified display with perfect ASCII art alignment"""
        lines = []

        # Main container with no right border for that leet look
        lines.append("    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        lines.append("    â•‘ HARDWARE MATRIX âˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆâˆ")
        lines.append("    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

        # Hardware topology section
        for i, device in enumerate(self.backend.devices):
            device_name = self.backend.get_device_name(device)
            board_type = self.backend.device_infos[i].get('board_type', 'Unknown')
            telem = self.backend.device_telemetrys[i]

            power = float(telem.get('power', '0.0'))
            temp = float(telem.get('asic_temperature', '0.0'))
            current = float(telem.get('current', '0.0'))
            voltage = float(telem.get('voltage', '0.0'))

            # Activity indicators with sick symbols
            if power > 50:
                activity = "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ"  # Full power bars
                status_char = "âš¡"
            elif power > 25:
                activity = "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘"  # High power
                status_char = "â—†"
            elif power > 10:
                activity = "â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘"  # Medium power
                status_char = "â—‡"
            else:
                activity = "â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘"  # Low power
                status_char = "â—‹"

            # Temperature status
            if temp > 80:
                temp_status = "ğŸ”¥CRIT"
            elif temp > 65:
                temp_status = "ğŸŒ¡HOT "
            elif temp > 45:
                temp_status = "ğŸŒ¡WARM"
            else:
                temp_status = "â„COOL"

            # Create flow visualization
            flow_intensity = min(int(current / 5), 20)
            if flow_intensity > 15:
                flow_pattern = "â–¶â–¶â–¶â–¶â–¶â–¶â–¶â–¶â–¶â–¶â–¶â–¶â–¶â–¶â–¶â–¶â–¶â–¶â–¶â–¶"[:flow_intensity]
            elif flow_intensity > 10:
                flow_pattern = "â–·â–·â–·â–·â–·â–·â–·â–·â–·â–·â–·â–·â–·â–·â–·â–·â–·â–·â–·â–·"[:flow_intensity]
            elif flow_intensity > 5:
                flow_pattern = "â–¸â–¸â–¸â–¸â–¸â–¸â–¸â–¸â–¸â–¸â–¸â–¸â–¸â–¸â–¸â–¸â–¸â–¸â–¸â–¸"[:flow_intensity]
            else:
                flow_pattern = "â–¹â–¹â–¹â–¹â–¹â–¹â–¹â–¹â–¹â–¹â–¹â–¹â–¹â–¹â–¹â–¹â–¹â–¹â–¹â–¹"[:flow_intensity]

            # Add animation offset
            offset = (self.animation_frame + i * 3) % len(flow_pattern) if flow_pattern else 0
            if flow_pattern:
                animated_flow = flow_pattern[offset:] + flow_pattern[:offset]
                animated_flow = animated_flow.ljust(20)
            else:
                animated_flow = "âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™"

            # Main device line with perfect alignment
            device_line = f"    â•‘ [{i:2d}] {device_name:10s} {status_char} {activity} {animated_flow} {temp_status}"
            lines.append(device_line)

            # Detail line with technical specs
            detail_line = f"    â•‘     â•°â”€> {board_type:8s} â”‚ {voltage:5.2f}V â”‚ {current:6.1f}A â”‚ {power:6.1f}W â”‚ {temp:5.1f}Â°C"
            lines.append(detail_line)

            if i < len(self.backend.devices) - 1:
                lines.append("    â•‘     âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™âˆ™")

        # Separator with sick ASCII
        lines.append("    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        lines.append("    â•‘ PROCESS MATRIX â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“")
        lines.append("    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")

        # Process table header with perfect spacing
        lines.append("    â•‘ ID â”‚ DEVICE     â”‚ BOARD  â”‚ VOLTAGE â”‚ CURRENT â”‚ POWER   â”‚ TEMP    â”‚ STATUS")
        lines.append("    â•‘â•â•â•â•â”¼â•â•â•â•â•â•â•â•â•â•â•â•â”¼â•â•â•â•â•â•â•â•â”¼â•â•â•â•â•â•â•â•â•â”¼â•â•â•â•â•â•â•â•â•â”¼â•â•â•â•â•â•â•â•â•â”¼â•â•â•â•â•â•â•â•â•â”¼â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        # Create device data sorted by power
        device_data = []
        for i, device in enumerate(self.backend.devices):
            device_name = self.backend.get_device_name(device)
            board_type = self.backend.device_infos[i].get('board_type', 'N/A')[:6]
            telem = self.backend.device_telemetrys[i]

            voltage = float(telem.get('voltage', '0.0'))
            current = float(telem.get('current', '0.0'))
            power = float(telem.get('power', '0.0'))
            temp = float(telem.get('asic_temperature', '0.0'))

            # Status with sick symbols
            if temp > 85:
                status = "ğŸš¨ CRITICAL"
            elif temp > 75:
                status = "ğŸ”¥ OVERHEATING"
            elif power > 75:
                status = "âš¡ HIGH_LOAD"
            elif power > 25:
                status = "ğŸŸ¢ ACTIVE"
            elif power > 5:
                status = "ğŸŸ¡ IDLE"
            else:
                status = "ğŸ’¤ SLEEP"

            device_data.append((i, device_name, board_type, voltage, current, power, temp, status))

        # Sort by power consumption
        device_data.sort(key=lambda x: x[5], reverse=True)

        # Add process rows with perfect alignment
        for i, device_name, board_type, voltage, current, power, temp, status in device_data:
            # Power visualization
            power_blocks = "â–ˆ" * int(power / 10) + "â–‘" * (10 - int(power / 10))

            line = f"    â•‘ {i:2d} â”‚ {device_name[:10]:10s} â”‚ {board_type:6s} â”‚ {voltage:7.2f}V â”‚ {current:7.1f}A â”‚ {power:7.1f}W â”‚ {temp:7.1f}Â°C â”‚ {status}"
            lines.append(line)

            # Add a subtle power bar under each entry
            power_line = f"    â•‘    â”‚            â”‚        â”‚         â”‚         â”‚ {power_blocks} â”‚         â”‚"
            lines.append(power_line)

        # Footer with legend and sick ASCII
        lines.append("    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£")
        lines.append("    â•‘ LEGEND: âš¡High Load  â—†Active  â—‡Moderate  â—‹Idle  ğŸ”¥Critical  ğŸŒ¡Hot  â„Cool")
        lines.append("    â•‘ FLOWS:  â–¶â–¶High Traffic  â–·â–·Medium  â–¸â–¸Low  â–¹â–¹Minimal  âˆ™âˆ™Inactive")
        lines.append("    â•‘ POWER:  â–ˆâ–ˆFull  â–‘â–‘Empty  â”‚ Real-time refresh every 100ms")
        lines.append("    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

        # Add some cyber footer
        lines.append("")
        lines.append("    â–‘â–‘â–’â–’â–“â–“â–ˆâ–ˆ NEURAL LINK ESTABLISHED â–ˆâ–ˆâ–“â–“â–’â–’â–‘â–‘")
        lines.append(f"    â–‘â–‘â–’â–’â–“â–“â–ˆâ–ˆ FRAME: {self.animation_frame:06d} â–ˆâ–ˆâ–“â–“â–’â–’â–‘â–‘")

        return lines

    def _create_chip_grid(self) -> List[str]:
        """Create the chip grid visualization"""
        grid_lines = []

        grid_lines.append("â”Œâ”€ Hardware Topology & Activity â”€â”€â”€â”€â”€â”€â”€â”€â”")
        grid_lines.append("â”‚                                        â”‚")

        for i, device in enumerate(self.backend.devices):
            device_name = self.backend.get_device_name(device)
            board_type = self.backend.device_infos[i].get('board_type', 'Unknown')

            # Get current telemetry
            telem = self.backend.device_telemetrys[i]
            voltage = float(telem.get('voltage', '0.0'))
            current = float(telem.get('current', '0.0'))
            temp = float(telem.get('asic_temperature', '0.0'))
            power = float(telem.get('power', '0.0'))

            # Activity symbol (plain text)
            if power > 50:
                activity_symbol = "â—"  # High activity
            elif power > 20:
                activity_symbol = "â—"  # Moderate activity
            elif power > 5:
                activity_symbol = "â—‹"  # Low activity
            else:
                activity_symbol = "Â·"  # Idle

            # Temperature indicator (plain text)
            if temp > 80:
                temp_color = "ğŸ”¥"
            elif temp > 60:
                temp_color = "ğŸŒ¡"
            elif temp > 40:
                temp_color = "ğŸŒ¡"
            else:
                temp_color = "â„"

            # Power bar (simplified to avoid markup conflicts)
            bar_length = 8
            filled = int((power / 100) * bar_length)
            power_bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)

            # Format lines
            chip_line = f"â”‚ [{i:2}] {device_name:10} {activity_symbol} {temp_color}â”‚"
            detail_line = f"â”‚     {board_type:10} {power_bar} {temp:4.1f}Â°C â”‚"

            grid_lines.append(chip_line)
            grid_lines.append(detail_line)

            if i < len(self.backend.devices) - 1:
                grid_lines.append("â”‚                                        â”‚")

        grid_lines.append("â”‚                                        â”‚")
        grid_lines.append("â”‚ Legend: â— Active  â—‹ Idle  â— Moderate  â”‚")
        grid_lines.append("â”‚         ğŸ”¥ Hot    â„ï¸ Cool   âš¡ High Pwr â”‚")
        grid_lines.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

        return grid_lines

    def _create_flow_visualization(self) -> List[str]:
        """Create the flow visualization"""
        flows = []

        flows.append("â”Œâ”€ Live Data Streams â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        flows.append("â”‚                                        â”‚")

        for i, device in enumerate(self.backend.devices):
            telem = self.backend.device_telemetrys[i]
            current = float(telem.get('current', '0.0'))

            # Create flow indicators
            flow_intensity = min(int(current / 10), 10)

            # Generate animated flow
            width = 20
            if flow_intensity == 0:
                flow_chars = " " * width
            else:
                flow_pattern = "â–¶â–·â–¶â–·" if flow_intensity > 5 else "â–¸â–¹â–¸â–¹"
                pattern_len = len(flow_pattern)

                offset = (self.animation_frame + i * 2) % pattern_len
                extended_pattern = (flow_pattern * (width // pattern_len + 2))[offset:offset + width]

                result = ""
                for j, char in enumerate(extended_pattern):
                    if j % (11 - flow_intensity) == 0:
                        result += char  # Plain text without color markup
                    else:
                        result += " "
                flow_chars = result[:width]

            device_name = self.backend.get_device_name(device)[:8]
            flow_line = f"â”‚ {device_name:8} â”‚{flow_chars}â”‚ {current:5.1f}A â”‚"
            flows.append(flow_line)

        flows.append("â”‚                                        â”‚")
        flows.append("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

        return flows

    def _combine_panels_horizontally(self, left_panel: List[str], right_panel: List[str]) -> List[str]:
        """Combine two panels horizontally"""
        combined = []
        max_lines = max(len(left_panel), len(right_panel))

        for i in range(max_lines):
            left_line = left_panel[i] if i < len(left_panel) else " " * 42
            right_line = right_panel[i] if i < len(right_panel) else " " * 42
            combined.append(f"{left_line}  {right_line}")

        return combined

    def _create_process_table(self) -> str:
        """Create the process table as a formatted string"""
        lines = []

        lines.append("â”Œâ”€ Live Hardware Processes & Activity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        lines.append("â”‚ ID â”‚ Device     â”‚ Board  â”‚ Voltage â”‚ Current â”‚ Power   â”‚ Temp    â”‚ AICLK   â”‚ Status   â”‚")
        lines.append("â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")

        # Create device data and sort by power
        device_data = []
        for i, device in enumerate(self.backend.devices):
            device_name = self.backend.get_device_name(device)
            board_type = self.backend.device_infos[i].get('board_type', 'N/A')[:6]
            telem = self.backend.device_telemetrys[i]

            voltage = float(telem.get('voltage', '0.0'))
            current = float(telem.get('current', '0.0'))
            power = float(telem.get('power', '0.0'))
            temp = float(telem.get('asic_temperature', '0.0'))
            aiclk = int(float(telem.get('aiclk', '0')))

            # Determine status using systematic method
            status = self._get_device_status_text(i)

            device_data.append((i, device_name, board_type, voltage, current, power, temp, aiclk, status))

        # Sort by power consumption
        device_data.sort(key=lambda x: x[5], reverse=True)

        # Add rows
        for data in device_data:
            i, device_name, board_type, voltage, current, power, temp, aiclk, status = data

            power_str = f"{power:6.1f}W"
            temp_str = f"{temp:5.1f}Â°C"

            # Create the line without embedded markup for table alignment
            line = f"â”‚ {i:2} â”‚ {device_name[:10]:10} â”‚ {board_type:6} â”‚ {voltage:6.2f}V â”‚ {current:6.1f}A â”‚ {power_str:>7} â”‚ {temp_str:>7} â”‚ {aiclk:6}MHz â”‚"

            # Add status separately to avoid markup conflicts
            if temp > 85:
                line += " CRITICAL â”‚"
            elif temp > 75:
                line += " HOT      â”‚"
            elif power > 75:
                line += " HIGH LOADâ”‚"
            elif power > 25:
                line += " ACTIVE   â”‚"
            elif power > 5:
                line += " IDLE     â”‚"
            else:
                line += " SLEEP    â”‚"

            lines.append(line)

        lines.append("â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")

        return "\n".join(lines)

    def _create_compact_header(self) -> List[str]:
        """Create compact TENSTORRENT header that disappears after 5 seconds"""
        lines = []

        # Calculate system health for color responsiveness
        total_devices = len(self.backend.devices)
        if total_devices == 0:
            system_status = "NO DEVICES"
            avg_temp, total_power = 0, 0
        else:
            # Get average temperature and power across all devices
            avg_temp = sum(float(self.backend.device_telemetrys[i].get('asic_temperature', '0'))
                          for i in range(total_devices)) / total_devices
            total_power = sum(float(self.backend.device_telemetrys[i].get('power', '0'))
                             for i in range(total_devices))

            if avg_temp > 80:
                system_status = "THERMAL WARNING"
            elif avg_temp > 65:
                system_status = "ELEVATED TEMP"
            elif total_power > 200:
                system_status = "HIGH POWER"
            elif total_power > 50:
                system_status = "ACTIVE"
            else:
                system_status = "READY"

        # Get logo color using systematic method
        logo_color = self._get_status_color(avg_temp, total_power)

        # Compact 3-line logo
        lines.append(f"    [bright_cyan]â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[/bright_cyan]")
        lines.append(f"    [bright_cyan]â•‘[/bright_cyan] [bold {logo_color}]TENSTORRENT â€¢ tt-top[/bold {logo_color}] [dim white]â”‚[/dim white] [bright_white]Status:[/bright_white] [{logo_color}]{system_status}[/{logo_color}] [dim white]â”‚[/dim white] [bright_white]Devices:[/bright_white] {total_devices} [dim white](Auto-hide in 5s)[/dim white]")
        lines.append(f"    [bright_cyan]â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•[/bright_cyan]")

        return lines

    def _create_bbs_main_display(self) -> List[str]:
        """Create main BBS-style display with terminal aesthetic - borderless right side"""
        lines = []

        # BBS-style system status header (borderless right) with cyberpunk colors
        lines.append("[bright_cyan]â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [bold bright_white]SYSTEM STATUS[/bold bright_white][/bright_cyan]")
        lines.append("[bright_cyan]â”‚[/bright_cyan]")

        # Hardware grid in retro style with colors
        for i, device in enumerate(self.backend.devices):
            device_name = self.backend.get_device_name(device)[:10]  # Truncate to fit
            board_type = self.backend.device_infos[i].get('board_type', 'Unknown')[:8]
            telem = self.backend.device_telemetrys[i]

            power = float(telem.get('power', '0.0'))
            temp = float(telem.get('asic_temperature', '0.0'))
            current = float(telem.get('current', '0.0'))
            voltage = float(telem.get('voltage', '0.0'))

            # Get systematic status indicators
            status_block, status_icon = self._get_status_indicator(power)

            # Temperature readout with systematic color coding
            temp_display = f"{temp:05.1f}Â°C"
            temp_color = self._get_temperature_color(temp)
            if temp > 80:
                temp_status = self._colorize_text("CRIT", "bold red")
            elif temp > 65:
                temp_status = self._colorize_text(" HOT", temp_color)
            elif temp > 45:
                temp_status = self._colorize_text("WARM", temp_color)
            else:
                temp_status = self._colorize_text("COOL", temp_color)

            # Memory activity pattern based on real power consumption
            memory_banks = self._generate_memory_pattern(power, i)
            # Color the memory banks based on activity
            colored_memory = ""
            for bank in memory_banks:
                if bank == "â—":
                    colored_memory += "[bright_magenta]â—[/bright_magenta]"
                else:
                    colored_memory += "[dim white]â—¯[/dim white]"

            # Create BBS-style device entry with colors
            device_line = f"[bright_cyan]â”‚[/bright_cyan] [bright_white]\\[[/bright_white][orange1]{i}[/orange1][bright_white]\\][/bright_white] [bold bright_white]{device_name:10s}[/bold bright_white] {status_icon} [bright_cyan]â”‚[/bright_cyan]{status_block}[bright_cyan]â”‚[/bright_cyan] [bright_white]{temp_display}[/bright_white] {temp_status}"
            lines.append(device_line)

            # Technical readout line with subtle colors
            tech_line = f"[bright_cyan]â”‚[/bright_cyan]     [dim bright_white]{board_type:8s}[/dim bright_white] {colored_memory} [bright_cyan]{voltage:4.2f}V[/bright_cyan] [bright_green]{current:5.1f}A[/bright_green] [orange1]{power:5.1f}W[/orange1]"
            lines.append(tech_line)

            # Interconnect activity flow based on real current draw
            flow_line = self._create_data_flow_line(current, i)
            # Color the flow indicators
            colored_flow = ""
            for char in flow_line:
                if char in "â–¶â–·":
                    colored_flow += f"[bright_magenta]{char}[/bright_magenta]"
                elif char in "â–¸â–¹":
                    colored_flow += f"[bright_cyan]{char}[/bright_cyan]"
                else:
                    colored_flow += f"[dim white]{char}[/dim white]"

            activity_line = f"[bright_cyan]â”‚[/bright_cyan]     [dim bright_white]DATA:[/dim bright_white] {colored_flow}"
            lines.append(activity_line)

            if i < len(self.backend.devices) - 1:
                lines.append("[bright_cyan]â”‚[/bright_cyan] [dim white]Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·[/dim white]")

        lines.append("[bright_cyan]â”‚[/bright_cyan]")
        lines.append("[bright_cyan]â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[/bright_cyan]")

        # Add temporal heatmap section in BBS style
        lines.append("")
        lines.extend(self._create_bbs_heatmap_section())

        # Add interconnect matrix in BBS style
        lines.append("")
        lines.extend(self._create_bbs_interconnect_section())

        # Add live hardware event log
        lines.append("")
        lines.extend(self._create_live_hardware_log())

        # Add enhanced memory hierarchy matrix visualization
        lines.append("")
        lines.extend(self._create_memory_hierarchy_matrix())

        # Add intelligent workload detection section
        lines.append("")
        lines.extend(self._create_workload_detection_section())

        # Real hardware status footer with ARC health monitoring
        lines.append("")
        total_devices = len(self.backend.devices)
        active_devices = sum(1 for i in range(total_devices)
                           if float(self.backend.device_telemetrys[i].get('heartbeat', '0')) > 0)
        total_power = sum(float(self.backend.device_telemetrys[i].get('power', '0'))
                         for i in range(total_devices))

        # Get real ARC firmware health status from telemetry
        arc_status = "OK"
        ddr_trained_count = 0
        for i in range(total_devices):
            try:
                if self.backend.get_dram_training_status(i):
                    ddr_trained_count += 1
            except:
                pass

        # Calculate real system metrics from telemetry
        avg_temp = sum(float(self.backend.device_telemetrys[i].get('asic_temperature', '0'))
                      for i in range(total_devices)) / max(total_devices, 1)
        avg_aiclk = sum(float(self.backend.device_telemetrys[i].get('aiclk', '0'))
                       for i in range(total_devices)) / max(total_devices, 1)

        lines.append("[bright_cyan]â”Œâ”€ [bold bright_white]HARDWARE STATUS[/bold bright_white] â”€â”€â”€â”€â”€â”€ [bright_cyan]â”Œâ”€ [bold bright_white]MEMORY STATUS[/bold bright_white] â”€â”€â”€â”€ [bright_cyan]â”Œâ”€ [bold bright_white]SYSTEM METRICS[/bold bright_white][/bright_cyan]")

        # Color code device status
        device_status_color = "bright_green" if active_devices == total_devices else "orange3" if active_devices > 0 else "red"
        ddr_status_color = "bright_green" if ddr_trained_count == total_devices else "orange3" if ddr_trained_count > 0 else "red"

        # Color code temperature
        temp_color = "red" if avg_temp > 80 else "orange3" if avg_temp > 65 else "bright_green"

        lines.append(f"[bright_cyan]â”‚[/bright_cyan] [bright_white]DEVICES:[/bright_white] [{device_status_color}]{active_devices}/{total_devices} ACTIVE[/{device_status_color}]     [bright_cyan]â”‚[/bright_cyan] [bright_white]DDR TRAINED:[/bright_white] [{ddr_status_color}]{ddr_trained_count}/{total_devices}[/{ddr_status_color}]   [bright_cyan]â”‚[/bright_cyan] [bright_white]TOTAL PWR:[/bright_white] [orange1]{total_power:5.1f}W[/orange1]")
        lines.append(f"[bright_cyan]â”‚[/bright_cyan] [bright_white]ARC HEARTBEATS:[/bright_white] [bright_green]{arc_status}[/bright_green]     [bright_cyan]â”‚[/bright_cyan] [bright_white]CHANNELS:[/bright_white] [bright_cyan]ACTIVE[/bright_cyan]     [bright_cyan]â”‚[/bright_cyan] [bright_white]AVG TEMP:[/bright_white] [{temp_color}]{avg_temp:5.1f}Â°C[/{temp_color}]")
        lines.append(f"[bright_cyan]â”‚[/bright_cyan] [bright_white]FRAMES:[/bright_white] [bright_magenta]{self.animation_frame:06d}[/bright_magenta]        [bright_cyan]â”‚[/bright_cyan] [bright_white]REFRESH:[/bright_white] [bright_green]100ms[/bright_green]       [bright_cyan]â”‚[/bright_cyan] [bright_white]AVG AICLK:[/bright_white] [bright_cyan]{avg_aiclk:4.0f}MHz[/bright_cyan]")
        lines.append("[bright_cyan]â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[/bright_cyan]")

        return lines

    def _create_bbs_heatmap_section(self) -> List[str]:
        """Create BBS-style temporal heatmap with cyberpunk colors - borderless right side"""
        lines = []
        lines.append("[bright_cyan]â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [bold bright_white]TEMPORAL ACTIVITY ANALYSIS[/bold bright_white][/bright_cyan]")
        lines.append("[bright_cyan]â”‚[/bright_cyan] [bright_white]DEVICE[/bright_white]     [bright_cyan]â”‚[/bright_cyan] [bright_white]ACTIVITY HISTORY (LAST 60 SECONDS)[/bright_white]       [bright_cyan]â”‚[/bright_cyan] [bright_white]NOW[/bright_white]")
        lines.append("[bright_cyan]â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€[/bright_cyan]")

        chars = " Â·âˆ™â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆ"
        char_colors = ["dim white", "dim white", "dim white", "bright_cyan", "bright_cyan", "bright_green", "orange1", "orange3", "red", "bold red", "bold red"]

        for i, device in enumerate(self.backend.devices):
            device_name = self.backend.get_device_name(device)[:10]
            telem = self.backend.device_telemetrys[i]
            power = float(telem.get('power', '0.0'))

            # Generate heatmap based on current power (not fake historical data)
            # In real implementation, this would use a rolling buffer of historical power data
            heatmap = ""
            current_intensity = min(int(power / 10), len(chars) - 1)

            # Show consistent pattern based on current power level
            # This represents the current activity level across the timeline
            for t in range(39):  # 39 characters for timeline
                # Use current power level as baseline (real data)
                # Add minimal variation to show it's "historical" but based on real current state
                if power > 0:
                    intensity = max(0, current_intensity - abs(t - 19) // 8)  # Peak in middle, taper at edges
                else:
                    intensity = 0

                char = chars[min(intensity, len(chars) - 1)]
                color = char_colors[min(intensity, len(char_colors) - 1)]
                heatmap += f"[{color}]{char}[/{color}]"

            # Current power indicator with colors
            if power > 50:
                current_indicator = "[bold red]â–ˆâ–ˆâ–ˆâ–ˆ[/bold red]"
            elif power > 25:
                current_indicator = "[bold orange3]â–ˆâ–ˆâ–ˆ[/bold orange3][dim white]â–“[/dim white]"
            elif power > 10:
                current_indicator = "[bright_green]â–ˆâ–ˆ[/bright_green][dim white]â–“â–“[/dim white]"
            else:
                current_indicator = "[dim white]â–“â–“â–“â–“[/dim white]"

            line = f"[bright_cyan]â”‚[/bright_cyan] [bold bright_white]{device_name:10}[/bold bright_white] [bright_cyan]â”‚[/bright_cyan] {heatmap} [bright_cyan]â”‚[/bright_cyan] {current_indicator}"
            lines.append(line)

        lines.append("[bright_cyan]â”‚[/bright_cyan]            [bright_cyan]â”‚[/bright_cyan] [dim bright_white]â†‘60s    â†‘30s    â†‘10s    â†‘5s     â†‘NOW[/dim bright_white]    [bright_cyan]â”‚[/bright_cyan]")
        lines.append("[bright_cyan]â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€[/bright_cyan]")
        return lines

    def _create_bbs_interconnect_section(self) -> List[str]:
        """Create BBS-style interconnect matrix with cyberpunk colors - borderless right side"""
        lines = []

        # Borderless matrix with colors
        lines.append("[bright_cyan]â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [bold bright_white]INTERCONNECT BANDWIDTH MATRIX[/bold bright_white][/bright_cyan]")

        # Device labels header with colors
        device_labels = [self.backend.get_device_name(d)[:8] for d in self.backend.devices]
        header_content = "[bright_magenta]FROM\\TO[/bright_magenta]  [bright_cyan]â”‚[/bright_cyan] " + " [bright_cyan]â”‚[/bright_cyan] ".join(f"[bold bright_white]{name:8s}[/bold bright_white]" for name in device_labels)
        lines.append(f"[bright_cyan]â”‚[/bright_cyan] {header_content}")

        # Separator line
        separator_parts = ["â”€" * 8 for _ in device_labels]
        separator_content = "â”€" * 8 + "â”¼" + "â”¼".join(separator_parts)
        lines.append(f"[bright_cyan]â”œâ”€{separator_content}[/bright_cyan]")

        # Matrix rows with colored bandwidth indicators
        for i, device in enumerate(self.backend.devices):
            device_name = self.backend.get_device_name(device)[:8]
            utilizations = []

            for j in range(len(self.backend.devices)):
                if i == j:
                    utilizations.append("[dim bright_white]  SELF  [/dim bright_white]")
                else:
                    # Calculate bandwidth simulation
                    telem_i = self.backend.device_telemetrys[i]
                    telem_j = self.backend.device_telemetrys[j]
                    current_i = float(telem_i.get('current', '0.0'))
                    current_j = float(telem_j.get('current', '0.0'))

                    bandwidth = min(abs(current_i - current_j) * 2, 99)

                    utilizations.append(self._get_bandwidth_indicator(bandwidth))

            # Build row (no right border) with colors
            row_content = f"[bold bright_white]{device_name:8s}[/bold bright_white] [bright_cyan]â”‚[/bright_cyan] " + " [bright_cyan]â”‚[/bright_cyan] ".join(utilizations)
            lines.append(f"[bright_cyan]â”‚[/bright_cyan] {row_content}")

        # Bottom border (no right side)
        bottom_parts = ["â”€" * 8 for _ in device_labels]
        bottom_content = "â”€" * 8 + "â”´" + "â”´".join(bottom_parts)
        lines.append(f"[bright_cyan]â””â”€{bottom_content}[/bright_cyan]")

        # Legend with colors
        lines.append("[bright_cyan]â”Œâ”€ [bright_white]LEGEND[/bright_white][/bright_cyan]")
        lines.append("[bright_cyan]â”‚[/bright_cyan] [bold red]â–“â–“ HIGH (>50)[/bold red] [bold orange3]â–’â–’ MED (25-50)[/bold orange3] [bright_green]â–‘â–‘ LOW (10-25)[/bright_green]  [dim white]IDLE (<10)[/dim white]")
        lines.append("[bright_cyan]â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[/bright_cyan]")

        return lines

    def _create_live_hardware_log(self) -> List[str]:
        """Create live hardware event log tail with cyberpunk styling"""
        lines = []

        lines.append("[bright_cyan]â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ [bold bright_white]HARDWARE EVENT LOG[/bold bright_white] [dim bright_white](LAST 8 EVENTS)[/dim bright_white][/bright_cyan]")
        lines.append("[bright_cyan]â”‚[/bright_cyan] [dim bright_white]TIMESTAMP    â”‚ DEV â”‚ EVENT[/dim bright_white]")
        lines.append("[bright_cyan]â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[/bright_cyan]")

        # Generate real-time hardware events based on current telemetry
        current_time = int(time.time())
        log_entries = []

        for i, device in enumerate(self.backend.devices):
            device_name = self.backend.get_device_name(device)[:3].upper()
            telem = self.backend.device_telemetrys[i]

            power = float(telem.get('power', '0.0'))
            temp = float(telem.get('asic_temperature', '0.0'))
            current = float(telem.get('current', '0.0'))
            voltage = float(telem.get('voltage', '0.0'))
            aiclk = float(telem.get('aiclk', '0.0'))
            heartbeat = float(telem.get('heartbeat', '0'))

            # Generate hardware events based on current telemetry state
            timestamp_offset = (self.animation_frame + i) % 60
            event_time = current_time - timestamp_offset

            # Power state events using intelligent detection
            power_event_text = self.backend.get_workload_event_text(i, "power")
            if power_event_text:
                log_entries.append((event_time - 15, i, device_name, power_event_text))

            # Temperature events using intelligent detection
            thermal_event_text = self.backend.get_workload_event_text(i, "thermal")
            if thermal_event_text:
                log_entries.append((event_time - 2, i, device_name, thermal_event_text))

            # Current draw events using intelligent detection
            current_event_text = self.backend.get_workload_event_text(i, "current")
            if current_event_text:
                log_entries.append((event_time - 1, i, device_name, current_event_text))

            # Clock frequency events using intelligent detection
            clock_event_text = self.backend.get_workload_event_text(i, "clock")
            if clock_event_text:
                log_entries.append((event_time - 3, i, device_name, clock_event_text))

            # ARC heartbeat events
            if heartbeat > 0:
                log_entries.append((event_time - 30, i, device_name, f"[bright_green]ARC_HEARTBEAT[/bright_green] #{int(heartbeat)} [dim white](firmware ok)[/dim white]"))
            else:
                log_entries.append((event_time - 45, i, device_name, f"[bold red]ARC_TIMEOUT[/bold red] no heartbeat [dim white](firmware issue)[/dim white]"))

        # Sort by timestamp (most recent first) and take last 8 events
        log_entries.sort(key=lambda x: x[0], reverse=True)
        recent_events = log_entries[:8]

        for event_time, dev_idx, dev_name, message in recent_events:
            # Format timestamp
            time_str = f"{event_time % 100:02d}:{(event_time * 10) % 60:02d}"

            line = f"[bright_cyan]â”‚[/bright_cyan] [dim bright_white]{time_str}[/dim bright_white]      [bright_cyan]â”‚[/bright_cyan] [orange1]{dev_name}[/orange1] [bright_cyan]â”‚[/bright_cyan] {message}"
            lines.append(line)

        # Fill remaining slots if we have fewer than 8 events
        while len(lines) < 11:  # 3 header lines + 8 event lines
            lines.append("[bright_cyan]â”‚[/bright_cyan] [dim white]--:--[/dim white]      [bright_cyan]â”‚[/bright_cyan] [dim white]---[/dim white] [bright_cyan]â”‚[/bright_cyan] [dim white]waiting for events...[/dim white]")

        lines.append("[bright_cyan]â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€[/bright_cyan]")
        lines.append("[dim bright_white]Hardware telemetry events â€¢ 100ms refresh[/dim bright_white]")

        return lines


class TTLiveMonitor(Container):
    """
    Enhanced scrollable container for the TT-Top live monitoring interface.
    Supports arrow key navigation for extended content viewing.
    """

    # Define key bindings for scrollable navigation
    BINDINGS = [
        Binding("up", "scroll_up", "Scroll Up", show=False),
        Binding("down", "scroll_down", "Scroll Down", show=False),
        Binding("page_up", "page_up", "Page Up", show=False),
        Binding("page_down", "page_down", "Page Down", show=False),
        Binding("home", "scroll_home", "Go to Top", show=False),
        Binding("end", "scroll_end", "Go to Bottom", show=False),
    ]

    def __init__(self, backend: TTSMIBackend, **kwargs):
        super().__init__(**kwargs)
        self.backend = backend

    def compose(self) -> ComposeResult:
        """Compose the scrollable live monitor layout

        Creates a scrollable view to accommodate expanded memory visualizations
        and additional hardware insights that exceed typical terminal dimensions.
        """
        with ScrollView(id="tt_top_scroll"):
            yield TTTopDisplay(backend=self.backend, id="tt_top_display")

    def action_scroll_up(self) -> None:
        """Scroll up by one line"""
        scroll_view = self.query_one("#tt_top_scroll", ScrollView)
        scroll_view.scroll_relative(y=-1, animate=False)

    def action_scroll_down(self) -> None:
        """Scroll down by one line"""
        scroll_view = self.query_one("#tt_top_scroll", ScrollView)
        scroll_view.scroll_relative(y=1, animate=False)

    def action_page_up(self) -> None:
        """Scroll up by one page"""
        scroll_view = self.query_one("#tt_top_scroll", ScrollView)
        scroll_view.scroll_page_up(animate=False)

    def action_page_down(self) -> None:
        """Scroll down by one page"""
        scroll_view = self.query_one("#tt_top_scroll", ScrollView)
        scroll_view.scroll_page_down(animate=False)

    def action_scroll_home(self) -> None:
        """Scroll to top of content"""
        scroll_view = self.query_one("#tt_top_scroll", ScrollView)
        scroll_view.scroll_home(animate=False)

    def action_scroll_end(self) -> None:
        """Scroll to bottom of content"""
        scroll_view = self.query_one("#tt_top_scroll", ScrollView)
        scroll_view.scroll_end(animate=False)